### 进程和线程的区别：
根本区别：进程是系统资源分配的基本单位，线程是任务调度和执行的基本单位。

开销方面：每个进程都有独立的代码和数据空间，程序之间的切换会有较大的开销；线程可以看做轻量级进程，同一类线程共享进程空间中的一些资源，包括共享代码和数据空间等，每个线程都有自己独立的运行栈和程序计数器（PC），线程之间切换开销小。

所处环境：操作系统中能同时运行多个进程，而同一个进程中可以有多个线程同时执行。进程相当于线程的容器，线程不能和进程那样单独存在，用户地址空间必须依托于进程。

内存分配方面：系统在运行的时候，会为每个进程分配不同的内存空间，而对线程而言，除了CPU，系统不会为线程分配内存（所使用的资源来自于所属的进程），线程之间只能共享资源。

###  协程
是一种用户态线程，对称协程和非对称协程。
协程不是操作系统管理的，而是完全由用户程序控制，也就是在用户态执行。
协程是一种特殊函数，可以在某个地方挂起，并且重新在挂起处外去执行，所以，协程与进程线程相比不是一个维度。一个线程内部可以有多个特殊函数运行，但是必须要明确的是，一个线程的多个协程运行是串行的。
如果是多核CPU，一个进程中的多个线程是可以并行的，但是一个线程内部的协程却绝对是并行，不能利用CPU多核能力。

协程的切换者使用户，切换时机是用户自己的程序所决定的，协程切换的内容是硬件上下文，切换内存保存在用户自己的变量中，协程的切换过程只有用户态，没有陷入内和态。切换效率高。

###  nginx架构？为什么高性能？

每一个进程都运行一个工作进程，使硬件资源得到充分利用
每个工作进程都是单线程且独立运行的，抓取并处理新的连接
epoll　IO多路复用机制，每次只返回活跃事件列表
master-worker进程模型:一个master，多个worker，master管理worker，worker处理请求，且worker进程为单线程
worker进程用来处理基本的网络事件，master进程只管理worker进程
协程机制：将每个用户的请求对应到线程的某一个协程，然后在协程中，依靠epoll多路复用来完成同步调度开发lua脚本也是基于协程机制

- 进程的出现是为了更好的利用CPU资源使兵法成为可能
- 线程的出现为了降低上写文切换的消耗，提高系统的并发性，并突破一个进程只能干一样事的缺陷，使进程内并发称为可能
- 协程通过在线程内实现调度，避免了陷入内核级别的上下文切换造成性能损失，进而突破线程在IO的性能瓶颈

### 输入一个URL如何显示页面的过程？

在本地dns缓存查询url的实际ip地址

要是本地，没有缓存url的ip地址，就根据本地配置的域名服务器ip地址，查询dns域名服务器
域名服务器查询域名的ip有迭代和递归两种：
- 递归查询是一种dns服务器的查询模式，在该模式下dns服务器收到客户机请求必须使用准确的查询结果回复客户机。如果dns服务器本地
没有存储查询dns信息，那么该服务器会询问其他服务器，并将返回的查询结果交给客户机。

- 迭代查询：dns服务器另一种查询方式为迭代查询，dns服务器会向客户端提供其他能狗解析查询请求的dns服务器地址，当客户机发送查询请求时，dns服务器并不直接回复查询结果，而是告诉客户机另一台dns服务器地址，客户机再向这台dns服务器提交请求，依次循环直到返回查询的结果为止。
查询到ip地址后，默认端口是80，连接相应的服务器，会经过三次握手，建立连接后，发送http请求头，请求服务器资源，服务器解析请求头路径并返回响应消息，客户端收到消息，按照超文本格式显示在网页。

### tcp三次握手

由客户端刚发送syn和其自身的初始序列号ins1
服务接收到后，保存客户端初始序列号，并构造ack=ins1+1，syn=服务端初始序列号ins2，将其发送给客户端
客户端收到后，保存服务端初始序列号，并响应ack=ins2+1给服务器，完成三次握手

### 为什么需要三次握手？

保证tcp数据传输的可靠性

参考课本：为了防止失效连接请求报文段突然又传送到服务端，产生错误。或者因为网络中可能存在延迟的重复分组

### time_wait？

当服务器主动断开连接后，可能在此时会有其他的客户端已经发送了数据到服务端，但服务端已经关闭了，这时候要是服务端能再马上重启，则可能收到这些包，耗费服务器资源，所以在服务端关闭后，需要为五元组设置time_wait状态，
在time_wait状态后，网络中的数据就会消失。服务器中再次重启，就不会收到这些无效的报文段了。

>实现tcp全双工的终止。
当客户主动中断连接的时候，根据tcp协议，客户必须接收服务器的fin信息，并给予ack应答，因此客户需要维护状态信息，以便能回复ack，如果过程中　ack丢失，它能够重传，否则将产生错误，而处于time_wait状态没有关闭可以实现。
>允许老的重复分节在网络中消失。如果一个tcp链接关闭，过了一会又在相同的ip和端口建立新连接，tcp需要防止之前链接没有传完的数据在新的链接出现，而如果链接处于time_wait状态，就不会给这个相同IP和端口建立新的链接，之前没有传完的数据将会在time_wait结束前在网络中消失，因为time_wait的持续时间是数据的生存时间msl的两倍

### tcp的粘包？

tcp粘包是一个伪概念，因为tcp本身是一种流式协议，不存在包的概念，当时对于利用tcp进行通信的应用层来说，分包是基本需求、。
分包是指在发送一个消息或者一帧数据时，通过一定的处理，令接受方能从字节流中识别并戳取出一个个消息包。

对于短链接的tcp服务，分包不是问题，只要发送方主动关闭连接，表示一条消息发送完成，接收方read返回0，从而得知消息结尾。
对于长连接的tcp服务，分包有4种做法：
定长包
使用特殊的字符作为消息边界
在每条消息的头部加一个长度字段
利用消息本身的格式来分包，比如json等

### 网络模型分几个层次？

有七层协议：自上而下
应用层：提供应用系统所需要的信息交换和远程操作，还充当应用过程的用户代理，完成信息交换所需的一些功能
表示层：处理两个通信系统之间交换信息的表示
为上层用户解决用户信息的语法问题，包括数据格式交换、数据加解密，等
会话层：在两个节点之间建立端到端的链接
管理两个用户和进程之间的对话
传输层：是网络体系结构中的高低层之间的接口层，整个分析体系结构协议的核心
提供全双工或半双工、流控制和错误恢复服务，传输层将消息分成若干组，并在接收端重新组织他们，可以通过不同的链接将不同的分组发送到主机。
网络层：通过寻址建立两个节点之间的链接，为源的传输层发送的数据包选择合适的路由和交换节点
负责建立和维护链接，控制网络拥塞，并在必要时生成计费信息
链路层：数据被框定，流控制被处理。为网络层提供数据链路链接，并对可能出错的物理链接执行几乎无错误的数据传输
指定拓扑和硬件寻址，常用设备包括电桥和开关
物理层：利用物理传输介质，为数据链路提供物理连接，实现比特流的特殊传输

四层协议：
应用层
传输层
网络层
链路层

### tcp和udp（用户数据报协议）的区别？

基于无连接和有链接
对系统资源的要求多少
udp程序结构胶简单，tcp则比较复杂
tcp是流协议，udp是数据报协议
tcp保证数据的正确性，udp可能丢包
tcp保证数据顺序，udp不保证

### 流量控制和拥塞控制？二者的区别？
- 流量控制：如果发送者发送过快，接受者来不及接收，那么就会有分组丢失，为了避免分组丢失，控制发送者的发送速度，使得接收者来的及接收，这就是流量控制。
- 根本目的：防止分组丢失，他是构成tcp可靠性的一方面
- 如何实现：由滑动窗口实现，滑动窗口协议保证了分组无差错，有序接收也实现了流量控制，主要的方式是接收方返回的ack中会包含自己的接受窗口的大小，并且利用大小来控制发送方的数据发送
- 流量控制引发的死锁？如何能避免？
当接受者接受到一个窗口为0的应答，发送者便停止发送，等待接受者的下一个应答，但是如果这个窗口不为0的应答在传输过程中丢失，发送者一直等待下去，而接受者以为发送者已经收到该应答，等待接受新数据，这样双方就相互等待，从而产生死锁。
避免流量控制引发的死锁，tcp使用了持续计时器，每当发送者收到一个０窗口的应答后，就启动该计时器，时间一到便主动发送报文询问接受者的窗口大小，若接受者仍然返回０窗口，则重置该计时器继续等待，若返回不为0，报文丢失了，此时重置发送窗口后开始发送

- 区别？
拥塞控制是作用于网络的，他是防止过多的数据注入到网络，避免出现网络负载过大的情况，常用的方法是：(1)慢开始，拥塞避免(2)快重传，快恢复

流量控制是作用于接收者，他是控制发送者的发送速度从而使接受者来得及接受，防止分组丢失

拥塞控制算法：
慢开始算法：发送方持续一个叫做拥塞窗口cwnd的状态变量，拥塞窗口的大小取决于网络的拥塞程度。并且动态地在变化，发送方让自己的发送窗口等于拥塞窗口，考虑到接受方的接受能力，发送窗口可能小于拥塞窗口
慢开始算法的思路不要一开始就发送大量的数据，先探测一下网络的拥塞程度，也就是有小到大增加拥塞窗口的大小
当cwnd<慢开始门限的时候，使用慢开始算法
当cwnd>慢开始门限，改用拥塞避免
当cwnd=慢开始门限　慢开始门限与拥塞避免算法任意

拥塞避免算法让拥塞窗口缓慢增长，每经过一个往返时间RTT，就将发送放的拥塞窗口cwnd加1，而不是加倍。

快重传算法？
要求接收放在收到一个失序报文段后就立即发出重复确认，而不要等到自己发送数据时捎带确认，该算法规定，
发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期

快恢复算法？
当发送方连续收到三个重复确认，就执行乘法减小算法，将满启动门限减半，但是接下去并不执行慢启动算法，执行拥塞避免算法将整个窗口缓慢增大

在采用快恢复算法时，慢开始算法只是在tcp连接建立的时候和网络出现超时时才使用

### 什么事平衡二叉树？

左右子树高度相差不超过1的树
可以使空树，要是不是空树，任何节点的左子树与右子树都是平衡二叉树，并且高度之差

### 快速排序和堆排序什么是稳定的？
稳定性的概念：在排序中存在两个相等的树，在排序完成后，这两个数的相对位置不变，就是稳定的排序。
都不是稳定的排序算法

### 单链表如何判断有环？找环的入口点？

1、从头节点开始，

快满指针解决

快满指针重合的地方打标记
将慢指针移动到链表首部，快指针和满指针同时以步长为1的单位遍历，满指针到达入口点的时候，快指针也就和满指针重合了


### tcp协议和IP协议的关系

tcp协议是一种传输层协议，IP是网络层协议
tcp协议负责将数据分成若干个数据包，并给每个数据包加上包头，包头上有相应的编号，以保证在数据接收端能将数据还原为原来的格式。IP协议在每个包头
上再加上接收端主机地址，这样数据找到自己要去的地方，如果传输过程中出现数据丢失，失真情况，tcp协议自动要求数据重传

###　tcp如何保证数据的可靠性？

确认和重传:接收方收到报文就会确认，发送方发送一段时间后没有收到确认就重传。
数据校验
数据合理分片和排序：udp，ip数据包大于1500，发送方IP就需要分片，将数据报分成若干片，使每一片都小于MTU，而接收方IP层则需要进行数据报的重组，这样要做许多事情，而更严重的是由于udp的特性，当某一片数据传送中丢失时，接收方便无法重组数据报，将丢弃整个数据包
tcp 按照MTU合理分片，接收方会缓存未按序到达的数据，重排后，再交给应用层
流量控制:当接收来不及的时候，提示发送方降低发送速率
拥塞控制:当网络拥塞的时候，减少数据的发送

### 发送端如何确认需要重传那些包？

在发送一段数据之后，就开启一个定时器，若是在这个时间内没有收到发送数据的ack确认报文，就对该报文进行重传。

### 为什么有滑动窗口？

因为发送端希望在收到确认之前继续发送其他报文段。提高信道利用率。需要一个缓冲区保存维护一个要发送数据的报文。

### tcp和http的关系，http是基于什么传送的？
tcp是传输层协议，http是应用层协议
tcp可对上层网络提供接口，使上层网络数据的传输建立在无差别的网络之上
http协议即超文本传输协议是web联网的基础，也是手机联网常用的协议之一，http协议时间里在tcp协议上的一种应用。
http在每次请求结束后，都会释放链接，因此http连接是一种短连接，要保持客户端程序在线状态需要不断向服务器发起链接请求
http 基于tcp/ip协议进行传输

### 为什么要有四次挥手？
为什么中间的ack和fin不合并为一起发送过来？
因为tcp是全双工模式，接收到fin时意味将没有数据再发来，但是还是可以继续发送数据。

原因：确保数据能完整传输。
关闭连接时，当收到对方的fin通知，它仅仅代表对方没有数据发送给你了，但未必你所有的数据都发送给对方了，
所以你可以未必马上会关闭socket，就是需要发送一些数据给对方之后，再发送fin报文给对方表示你同意可以关闭连接，这也是ack和fin分开发的原因

http和https的关系？

- http是超文本传输协议，属于明文传输协议，https则是安全型的基于ssl加密的传输协议
- http和https使用的是连接方式不同，而且用的端口也不一样，前者是80，后者是443
- http是简单的无状态的连接，https协议是由ssl+http协议构建的可进行加密传输、身份认证的网络，要比http协议更安全
- https内容经过对称加密，每个连接生成一个唯一的加密秘钥，(对称秘钥：对称秘钥加密又叫专用秘钥加密，即发送和接受数据的双方
必使用相同的秘钥对明文进行加密和解密。)

http和https都是应用还曾协议。https相比于http较安全


https协议握手阶段比较费时，会是页面的加载时间延长50%，增加10%到20%的耗电
https链接缓存不如http高效，会增加数据开销和功耗，甚至已有的安全的措施也会因此而受到影响
ssl证书需要钱


###　加密算法md5如何理解？
就是一种加密算法，只能加密，不能解密

### 智能指针
c++11中提供的两种智能指针

shared_ptr可以用来实现共享所有权的概念，多个智能指针可以引用同一个对象，当最后一个对象被智能指针销毁的时候，对象销毁，
为了使智能指针可以适用于更复杂的场景，weak_ptr，bad_weak_ptr和enable_shared_from_this

unique_ptr可用用来实现互斥所有权的概念，在一段时间内，只有一个智能指针可以指向对象，当然，这种所有权是可以转移的，这种智能指针可以有效地避免资源泄露，比如忘记delete来释放堆对象
他对持有的对象有独有权，两个unique_ptr不能指向一个对象，即unique_ptr不共享他所管理的对象，他无法复制到其他unique_ptr。
使用weak_ptr的主要原因是不想关注资源的释放，但是在某些情况下shared_ptr会出现错误，或者失效。

循环引用问题：如果两个对象使用shared_ptr指向彼此，当释放的时候，就不会自动释放资源，因为引用计数的计算有问题

当对象共享的时候，指针的声明期要长于对象。因此，对象不会被删除，指针也就无法注意到对象是否释放


### http里面的消息头？最常用的消息头

get请求，post请求，put，delete请求
常用的就是get请求　post请求

get请求一般请求获取数据，post请求一般做作为发送数据到后台使用

get请求也可以传参数到后台，但是其参数在浏览器的地址栏中可见，所以隐私安全较差，且参数长度也是有限制的
post请求传递参数放在request body中不会再url中显示，比get要安全，且参数长度无限制

get 请求刷新浏览器回退没有影响，post回退时重新提交数据请求
get请求可被缓存，post请求不会被缓存


###　多进程和多线陈模型？

多进程的优点：

- 每个进程互相独立，不影响主程序的稳定性，子进程崩溃没关系

- 通过增加CPU可以容易扩充性能

- 可以尽量减少线程加锁解锁的影响，极大提高性能，就算是线程运行的模块算法效率低也没关系

- 每个子进程都有2GB地址空间和相关资源，总体能够达到的性能上限非常大

对进程的缺点：

- 控制逻辑复杂，需要和主程序交互；

- 需要跨进程边界，如果有大量数据传送，就不太好，适合小数据量传送，密集运算，多进程调度开销比较大

- 最好是多进程和多线程结合，即根据实际的需要，每个CPU开启一个子进程，这个子进程开启多线程可以为若干同类型的数据进行处理，当然你也可以利用多线程+多CPU+轮训方式解决


多线程的缺点：

- 每个线程与主程序共用地址空间，受限于2GB地址空间
- 线程之间的同步和加锁控制比较麻烦
- 一个线程的崩溃可能影响到整个程序的稳定性
- 到达一定线程数量程度后，即使再增加CPU也无法提高性能
-　线程调度麻烦，需要耗费CPU资源


